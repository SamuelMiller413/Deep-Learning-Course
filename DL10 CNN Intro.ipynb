{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSlqSSC-1nAO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision as tv\n",
        "\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wq_ch3ZZLYmH"
      },
      "outputs": [],
      "source": [
        "url = 'https://media.istockphoto.com/vectors/chess-silhouettes-vector-id165635822?b=1&k=20&m=165635822&s=612x612&w=0&h=pmf6FVa--nzyWCKb0SyTkIi3xdaHaamJuaR-FIjw1iI='\n",
        "response = requests.get(url)\n",
        "img = Image.open(BytesIO(response.content)).convert('L')\n",
        "img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFlFdiI4S7J6"
      },
      "outputs": [],
      "source": [
        "to_tensor = tv.transforms.ToTensor()\n",
        "to_image = tv.transforms.ToPILImage()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjP50az6Rdnh"
      },
      "outputs": [],
      "source": [
        "img_tensor = (\n",
        "    to_tensor(img) # Convert to tensor\n",
        "    .unsqueeze(0) # Add a batch dimension\n",
        "    / 255. # Scale between 0 and 1.\n",
        ")\n",
        "img_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7LA-TaGKhp2"
      },
      "outputs": [],
      "source": [
        "vertical_filter = torch.tensor([\n",
        "    [1., 0, -1],\n",
        "    [1., 0, -1],\n",
        "    [1., 0, -1],\n",
        "]).unsqueeze(0).unsqueeze(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YI_ss_TqKHZg"
      },
      "outputs": [],
      "source": [
        "vert_output = F.conv2d(img_tensor, vertical_filter).squeeze()\n",
        "vert_image = to_image(vert_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xsyg5iTATCV4"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
        "axes[0].imshow(img, cmap='Greys_r')\n",
        "axes[0].set_title('Original greyscale image')\n",
        "axes[1].imshow(vert_image, cmap='Greys_r')\n",
        "axes[1].set_title('Feature map of vertical filter')\n",
        "for ax in axes:\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anrR11WXu7_L"
      },
      "source": [
        "# Exercise 10.1\n",
        "\n",
        "Use what you learned in this lesson to create a horizontal feature map.\n",
        "The result of this exercise should be an edge detector that detects the top edges of the chess pieces and squares on the board.\n",
        "\n",
        "Then, use the `F.conv2d` to apply the filter.\n",
        "\n",
        "<!-- startquestion -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oC51Xvw8wWoD"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "horizontal_filter = ...\n",
        "\n",
        "horizontal_tensor = ...\n",
        "horizontal_image = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oWAWKCbwej1"
      },
      "outputs": [],
      "source": [
        "assert horizontal_filter.ndim == 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nodTP1FNwA0F"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
        "axes[0].imshow(img, cmap='Greys_r')\n",
        "axes[0].set_title('Original greyscale image')\n",
        "axes[1].imshow(horizontal_image, cmap='Greys_r')\n",
        "axes[1].set_title('Feature map of horizontal filter')\n",
        "for ax in axes:\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LSXV7pvxpiD"
      },
      "outputs": [],
      "source": [
        "two_filters = torch.cat([vertical_filter, horizontal_filter], dim=0)\n",
        "two_filters.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfTSAyM9zmEq"
      },
      "outputs": [],
      "source": [
        "two_filter_output = F.conv2d(img_tensor, two_filters)\n",
        "two_filter_output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-RdZJjrzz4V"
      },
      "outputs": [],
      "source": [
        "# unpack the filters into their own tensors\n",
        "vert_output, horizontal_output = two_filter_output.squeeze() \n",
        "# convert tensors to images\n",
        "vert_image = to_image(vert_output.squeeze())\n",
        "horizontal_image = to_image(horizontal_output.squeeze())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlQMBrYIz7KY"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
        "axes[0].imshow(vert_image, cmap='Greys_r')\n",
        "axes[0].set_title('Feature map of vertical filter')\n",
        "axes[1].imshow(horizontal_image, cmap='Greys_r')\n",
        "axes[1].set_title('Feature map of horizontal filter')\n",
        "for ax in axes:\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWacj1EV6MhK"
      },
      "outputs": [],
      "source": [
        "zero_pad = nn.ZeroPad2d(30)\n",
        "reflection_pad = nn.ReflectionPad2d(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXIHxf7eLmEZ"
      },
      "outputs": [],
      "source": [
        "to_image(zero_pad(img_tensor).squeeze() * 255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XM-4XLtZ7WzT"
      },
      "outputs": [],
      "source": [
        "to_image(reflection_pad(img_tensor).squeeze() * 255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1rMd1aOO0bm"
      },
      "outputs": [],
      "source": [
        "assert img_tensor.shape == F.conv2d(img_tensor, vertical_filter, padding='same').shape\n",
        "assert img_tensor.shape == F.conv2d(img_tensor, vertical_filter, padding=1).shape\n",
        "assert not img_tensor.shape == F.conv2d(img_tensor, vertical_filter).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNDcsnUDSo8P"
      },
      "outputs": [],
      "source": [
        "img_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebN_qqaRSW5W"
      },
      "outputs": [],
      "source": [
        "F.conv2d(img_tensor, vertical_filter, padding=1, stride=1).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5t55mbrSNDM"
      },
      "outputs": [],
      "source": [
        "F.conv2d(img_tensor, vertical_filter, padding=1, stride=2).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWEu1x09mkGh"
      },
      "outputs": [],
      "source": [
        "url = 'https://www.syfy.com/sites/syfy/files/styles/scale--1200/public/cast_futurama_bender_0.jpg'\n",
        "response = requests.get(url)\n",
        "img = Image.open(BytesIO(response.content)).resize((350, 500))\n",
        "img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6j7r7iuPbH8"
      },
      "outputs": [],
      "source": [
        "img_tensor = to_tensor(img).unsqueeze(0)\n",
        "img_tensor.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYr4l75QgWky"
      },
      "source": [
        "# Exercise 10.2\n",
        "\n",
        "Instead of explicitly defining filters, we'll just use random numbers this time.\n",
        "Based on the `F.conv2d` documentation, the filters should be of shape `(out_channels, in_channels, kernel/filter_height, kernel/filter_width)`.\n",
        "\n",
        "Complete the code in the cell below to create a filter with a 3x3 kernel that takes in a 3-channel image and returns a 16-channel feature map.\n",
        "We will use `F.conv2d` to generate the feature map.\n",
        "\n",
        "<!-- startquestion -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEJYUyPwhUdx"
      },
      "outputs": [],
      "source": [
        "out_channels = ...\n",
        "in_channels = ...\n",
        "kH = ...\n",
        "kW = ...\n",
        "try:\n",
        "    random_filters = torch.rand((out_channels, in_channels, kH, kW))\n",
        "    print(random_filters.shape)\n",
        "except:\n",
        "    print('Please assign out_channels, in_channels, kH, and kW.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvHjxp5giXK7"
      },
      "outputs": [],
      "source": [
        "outputs = F.conv2d(img_tensor, random_filters, padding=1, stride=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxI_1T0tPhQQ"
      },
      "outputs": [],
      "source": [
        "assert outputs.shape[1] == 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEOPp8lgQQwq"
      },
      "outputs": [],
      "source": [
        "conv_kwargs = {\n",
        "    'padding': 1,\n",
        "    'stride': 1\n",
        "}\n",
        "\n",
        "conv_layer = nn.Conv2d(3, 16, 3, **conv_kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DeR1-mO_2WwO"
      },
      "outputs": [],
      "source": [
        "conv_layer_output = conv_layer(img_tensor)\n",
        "conv_layer_output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRvH0jGyqoW3"
      },
      "outputs": [],
      "source": [
        "conv_function_output = F.conv2d(img_tensor, conv_layer.weight.data, conv_layer.bias.data, **conv_kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7Q0PmTJqxQP"
      },
      "outputs": [],
      "source": [
        "assert (conv_function_output == conv_layer_output).all()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbOFVavcUxkS"
      },
      "outputs": [],
      "source": [
        "maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "avgpool = nn.AvgPool2d(kernel_size=2, stride=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7R_fH_seVFoC"
      },
      "outputs": [],
      "source": [
        "print(f\"\"\"\n",
        "Oringinal image shape: {img_tensor.shape}\n",
        "Max pool tensor shape: {maxpool(img_tensor).shape}\n",
        "Avg pool tensor shape: {avgpool(img_tensor).shape}\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krpaM9ufWG89"
      },
      "outputs": [],
      "source": [
        "conv_stride_2 = nn.Conv2d(3, 3, 3, 2, 1)\n",
        "conv_then_pool = nn.Sequential(\n",
        "    nn.Conv2d(3, 3, 3, 1, 1),\n",
        "    nn.MaxPool2d(2, 2)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCWGU1JvW4C3"
      },
      "outputs": [],
      "source": [
        "print(f\"\"\"\n",
        "Shape of conv with a stride of 2: {conv_stride_2(img_tensor).shape}\n",
        "Shape of conv with a poolling layer: {conv_then_pool(img_tensor).shape}\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uz5vlmPNfS6e"
      },
      "outputs": [],
      "source": [
        "adapt_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "adapt_max_pool = nn.AdaptiveMaxPool2d(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_IEGeE2f7N2"
      },
      "outputs": [],
      "source": [
        "outputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7Owh1gGfXiV"
      },
      "outputs": [],
      "source": [
        "adapt_avg_pool(outputs).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqKoPFFef5By"
      },
      "outputs": [],
      "source": [
        "adapt_pool_with_flatten = nn.Sequential(\n",
        "    nn.AdaptiveMaxPool2d(1),\n",
        "    nn.Flatten()\n",
        ")\n",
        "\n",
        "print(adapt_pool_with_flatten(outputs).shape)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "10_Introduction_to_Convolutional_Neural_Nets.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}